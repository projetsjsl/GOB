/**
 * Script pour ajouter un choix entre Emma (Perplexity) et Gemini dans le workflow n8n
 * 
 * Structure:
 * 1. Ajouter un node "AI Model Config" pour choisir le modÃ¨le
 * 2. Ajouter un node IF "Choose AI Model?" aprÃ¨s "Prepare API Request"
 * 3. CrÃ©er un node "Call Gemini API" pour appeler directement Gemini
 * 4. Les deux branches (Emma et Gemini) convergent vers "Parse API Response"
 */

import { readFileSync, writeFileSync } from 'fs';

const workflowPath = 'n8n-workflow-03lgcA4e9uRTtli1.json';
const workflow = JSON.parse(readFileSync(workflowPath, 'utf-8'));

console.log('ðŸ”§ Ajout du choix entre Emma (Perplexity) et Gemini...\n');

// Trouver les nodes existants
const prepareApiRequestNode = workflow.nodes.find(n => n.name === 'Prepare API Request');
const callEmmaNode = workflow.nodes.find(n => n.name === 'Call /api/chat (Emma)');
const parseApiResponseNode = workflow.nodes.find(n => n.name === 'Parse API Response');

if (!prepareApiRequestNode || !callEmmaNode || !parseApiResponseNode) {
  console.error('âŒ Nodes requis non trouvÃ©s');
  process.exit(1);
}

console.log('âœ… Nodes existants trouvÃ©s');

// 1. CrÃ©er un node "AI Model Config" pour choisir le modÃ¨le
const aiModelConfigNode = {
  parameters: {
    assignments: {
      assignments: [
        {
          id: 'ai-model-choice',
          name: 'ai_model',
          value: 'emma', // 'emma' ou 'gemini'
          type: 'string'
        }
      ]
    },
    includeOtherFields: true,
    options: {}
  },
  id: 'ai-model-config-node',
  name: 'AI Model Config',
  type: 'n8n-nodes-base.set',
  typeVersion: 3.4,
  position: [
    prepareApiRequestNode.position[0] - 160,
    prepareApiRequestNode.position[1]
  ]
};

// VÃ©rifier si le node existe dÃ©jÃ 
const existingAiModelConfig = workflow.nodes.find(n => n.name === 'AI Model Config');
if (!existingAiModelConfig) {
  workflow.nodes.push(aiModelConfigNode);
  console.log('âœ… Node "AI Model Config" crÃ©Ã©');
} else {
  console.log('âœ… Node "AI Model Config" existe dÃ©jÃ ');
}

// 2. CrÃ©er un node IF "Choose AI Model?"
const chooseAiModelNode = {
  parameters: {
    conditions: {
      boolean: [
        {
          value1: "={{ $json.ai_model === 'emma' || $json.ai_model === undefined }}",
          value2: true
        }
      ]
    },
    options: {}
  },
  id: 'choose-ai-model-if',
  name: 'Choose AI Model?',
  type: 'n8n-nodes-base.if',
  typeVersion: 2,
  position: [
    prepareApiRequestNode.position[0] + 160,
    prepareApiRequestNode.position[1]
  ]
};

// VÃ©rifier si le node existe dÃ©jÃ 
const existingChooseAiModel = workflow.nodes.find(n => n.name === 'Choose AI Model?');
if (!existingChooseAiModel) {
  workflow.nodes.push(chooseAiModelNode);
  console.log('âœ… Node "Choose AI Model?" crÃ©Ã©');
} else {
  console.log('âœ… Node "Choose AI Model?" existe dÃ©jÃ ');
}

// 3. CrÃ©er un node "Call Gemini API" pour appeler directement Gemini
const callGeminiNode = {
  parameters: {
    method: 'POST',
    url: '=https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent',
    sendHeaders: true,
    headerParameters: {
      parameters: [
        {
          name: 'Content-Type',
          value: 'application/json'
        }
      ]
    },
    sendQuery: true,
    queryParameters: {
      parameters: [
        {
          name: 'key',
          value: '={{ $env.GEMINI_API_KEY }}'
        }
      ]
    },
    sendBody: true,
    specifyBody: 'json',
    jsonBody: `={{ {
  "contents": [{
    "parts": [{
      "text": $json.message || $json.selected_prompt || "GÃ©nÃ¨re un briefing financier matinal."
    }]
  }],
  "generationConfig": {
    "temperature": 0.7,
    "topK": 40,
    "topP": 0.95,
    "maxOutputTokens": 2048
  }
} }}`,
    options: {
      response: {
        response: {
          responseFormat: 'json'
        }
      }
    }
  },
  id: 'call-gemini-api-node',
  name: 'Call Gemini API',
  type: 'n8n-nodes-base.httpRequest',
  typeVersion: 4.2,
  position: [
    callEmmaNode.position[0],
    callEmmaNode.position[1] + 200
  ]
};

// VÃ©rifier si le node existe dÃ©jÃ 
const existingCallGemini = workflow.nodes.find(n => n.name === 'Call Gemini API');
if (!existingCallGemini) {
  workflow.nodes.push(callGeminiNode);
  console.log('âœ… Node "Call Gemini API" crÃ©Ã©');
} else {
  console.log('âœ… Node "Call Gemini API" existe dÃ©jÃ ');
}

// 4. CrÃ©er un node "Parse Gemini Response" pour adapter la rÃ©ponse Gemini au format attendu
const parseGeminiResponseNode = {
  parameters: {
    jsCode: `const items = $input.all();
const data = items[0].json;

// La rÃ©ponse de Gemini a une structure diffÃ©rente
// Structure Gemini: { candidates: [{ content: { parts: [{ text: "..." }] } }] }
let content = '';
if (data.candidates && data.candidates[0] && data.candidates[0].content && data.candidates[0].content.parts) {
  content = data.candidates[0].content.parts.map(part => part.text).join('\\n');
} else if (data.response) {
  content = data.response;
} else if (typeof data === 'string') {
  content = data;
}

// Adapter au format attendu par Parse API Response
return items.map(item => ({
  json: {
    ...item.json,
    newsletter_content: content,
    response: content,
    message: content,
    emma_model: 'gemini',
    emma_tools: [],
    emma_execution_time: 0,
    trigger_type: item.json.trigger_type || 'Manuel',
    prompt_type: item.json.prompt_type || 'custom',
    generated_at: new Date().toISOString(),
    // PrÃ©server preview_mode et approved
    preview_mode: item.json.preview_mode,
    approved: item.json.approved
  }
}));`
  },
  id: 'parse-gemini-response',
  name: 'Parse Gemini Response',
  type: 'n8n-nodes-base.code',
  typeVersion: 2,
  position: [
    parseApiResponseNode.position[0],
    parseApiResponseNode.position[1] + 200
  ]
};

// VÃ©rifier si le node existe dÃ©jÃ 
const existingParseGemini = workflow.nodes.find(n => n.name === 'Parse Gemini Response');
if (!existingParseGemini) {
  workflow.nodes.push(parseGeminiResponseNode);
  console.log('âœ… Node "Parse Gemini Response" crÃ©Ã©');
} else {
  console.log('âœ… Node "Parse Gemini Response" existe dÃ©jÃ ');
}

// 5. Mettre Ã  jour les connexions
// AI Model Config â†’ Prepare API Request
if (!workflow.connections['AI Model Config']) {
  workflow.connections['AI Model Config'] = {
    main: [
      [
        {
          node: 'Prepare API Request',
          type: 'main',
          index: 0
        }
      ]
    ]
  };
  console.log('âœ… Connexion: AI Model Config â†’ Prepare API Request');
}

// Prepare API Request â†’ Choose AI Model?
if (workflow.connections['Prepare API Request']) {
  // Remplacer la connexion directe vers Call /api/chat (Emma)
  workflow.connections['Prepare API Request'] = {
    main: [
      [
        {
          node: 'Choose AI Model?',
          type: 'main',
          index: 0
        }
      ]
    ]
  };
  console.log('âœ… Connexion: Prepare API Request â†’ Choose AI Model?');
} else {
  workflow.connections['Prepare API Request'] = {
    main: [
      [
        {
          node: 'Choose AI Model?',
          type: 'main',
          index: 0
        }
      ]
    ]
  };
  console.log('âœ… Connexion: Prepare API Request â†’ Choose AI Model? (crÃ©Ã©e)');
}

// Choose AI Model? â†’ Call /api/chat (Emma) (TRUE = Emma)
if (!workflow.connections['Choose AI Model?']) {
  workflow.connections['Choose AI Model?'] = {
    main: [
      // TRUE (index 0) â†’ Emma
      [
        {
          node: 'Call /api/chat (Emma)',
          type: 'main',
          index: 0
        }
      ],
      // FALSE (index 1) â†’ Gemini
      [
        {
          node: 'Call Gemini API',
          type: 'main',
          index: 0
        }
      ]
    ]
  };
  console.log('âœ… Connexion: Choose AI Model? â†’ Emma (TRUE) et Gemini (FALSE)');
} else {
  // Mettre Ã  jour les connexions existantes
  workflow.connections['Choose AI Model?'].main = [
    // TRUE â†’ Emma
    [
      {
        node: 'Call /api/chat (Emma)',
        type: 'main',
        index: 0
      }
    ],
    // FALSE â†’ Gemini
    [
      {
        node: 'Call Gemini API',
        type: 'main',
        index: 0
      }
    ]
  ];
  console.log('âœ… Connexions mises Ã  jour: Choose AI Model? â†’ Emma/Gemini');
}

// Call Gemini API â†’ Parse Gemini Response
if (!workflow.connections['Call Gemini API']) {
  workflow.connections['Call Gemini API'] = {
    main: [
      [
        {
          node: 'Parse Gemini Response',
          type: 'main',
          index: 0
        }
      ]
    ]
  };
  console.log('âœ… Connexion: Call Gemini API â†’ Parse Gemini Response');
}

// Parse Gemini Response â†’ Parse API Response (convergence)
if (!workflow.connections['Parse Gemini Response']) {
  workflow.connections['Parse Gemini Response'] = {
    main: [
      [
        {
          node: 'Parse API Response',
          type: 'main',
          index: 0
        }
      ]
    ]
  };
  console.log('âœ… Connexion: Parse Gemini Response â†’ Parse API Response');
}

// Call /api/chat (Emma) â†’ Parse API Response (connexion existante, vÃ©rifier)
if (workflow.connections['Call /api/chat (Emma)']) {
  const emmaConnections = workflow.connections['Call /api/chat (Emma)'].main[0];
  if (!emmaConnections || !emmaConnections.find(c => c.node === 'Parse API Response')) {
    workflow.connections['Call /api/chat (Emma)'] = {
      main: [
        [
          {
            node: 'Parse API Response',
            type: 'main',
            index: 0
          }
        ]
      ]
    };
    console.log('âœ… Connexion: Call /api/chat (Emma) â†’ Parse API Response (vÃ©rifiÃ©e)');
  }
} else {
  workflow.connections['Call /api/chat (Emma)'] = {
    main: [
      [
        {
          node: 'Parse API Response',
          type: 'main',
          index: 0
        }
      ]
    ]
  };
  console.log('âœ… Connexion: Call /api/chat (Emma) â†’ Parse API Response (crÃ©Ã©e)');
}

// 6. Mettre Ã  jour "Prepare API Request" pour prÃ©server ai_model
const prepareApiRequestCode = prepareApiRequestNode.parameters.jsCode || '';
if (!prepareApiRequestCode.includes('ai_model')) {
  const updatedCode = `const items = $input.all();
const data = items[0].json;

// Extract ticker symbols from input 1 (tickers data)
const tickers = items.filter(item => item.json.ticker).map(item => item.json.ticker);
const tickerList = tickers.join(', ');

// Normaliser le type de briefing
let briefingType = data.prompt_type;
if (briefingType === 'noon') {
  briefingType = 'midday';
}

// Construire le message pour /api/chat (qui utilise emma-agent) ou Gemini
const fullPrompt = \`\${data.selected_prompt}\\n\\nFocus sur ces tickers: \${tickerList}\`;

return [{
  json: {
    ...data,
    tickers: tickerList,
    briefing_type: briefingType,
    message: fullPrompt,
    channel: 'web',
    userId: 'n8n-automation',
    // PrÃ©server ai_model depuis AI Model Config
    ai_model: data.ai_model || 'emma'
  }
}];`;
  
  prepareApiRequestNode.parameters.jsCode = updatedCode;
  console.log('âœ… "Prepare API Request" mis Ã  jour pour prÃ©server ai_model');
}

// Sauvegarder
writeFileSync(workflowPath, JSON.stringify(workflow, null, 2), 'utf-8');

console.log('\nâœ… Workflow mis Ã  jour avec succÃ¨s !');
console.log('\nðŸ“‹ Structure du nouveau flux:');
console.log('   1. AI Model Config (choix: emma ou gemini)');
console.log('   2. Prepare API Request');
console.log('   3. Choose AI Model? (IF)');
console.log('      - TRUE â†’ Call /api/chat (Emma) â†’ Parse API Response');
console.log('      - FALSE â†’ Call Gemini API â†’ Parse Gemini Response â†’ Parse API Response');
console.log('   4. Parse API Response (convergence)');
console.log('   5. ... (reste du workflow)');
console.log('\nðŸ’¡ Pour changer de modÃ¨le:');
console.log('   Modifiez "ai_model" dans le node "AI Model Config"');
console.log('   - "emma" â†’ Utilise Emma (Perplexity) via /api/chat');
console.log('   - "gemini" â†’ Utilise Gemini directement');

