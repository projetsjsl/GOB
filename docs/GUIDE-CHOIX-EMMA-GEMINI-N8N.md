# üìñ Guide : Choix entre Emma (Perplexity) et Gemini dans n8n

## üéØ Vue d'ensemble

Le workflow n8n permet maintenant de choisir entre deux mod√®les d'IA :
- **Emma (Perplexity)** : Via l'API `/api/chat` qui utilise Perplexity avec fallback Gemini
- **Gemini** : Appel direct √† l'API Gemini dans n8n

## üîÑ Structure du Flux

```
Determine Time-Based Prompt
  ‚Üì
AI Model Config (choix: emma ou gemini)
  ‚Üì
Prepare API Request
  ‚Üì
Choose AI Model? (IF)
  ‚îú‚îÄ TRUE ‚Üí Call /api/chat (Emma) ‚Üí Parse API Response
  ‚îî‚îÄ FALSE ‚Üí Call Gemini API ‚Üí Parse Gemini Response ‚Üí Parse API Response
  ‚Üì
Parse API Response (convergence)
  ‚Üì
... (reste du workflow)
```

## ‚öôÔ∏è Configuration

### Node "AI Model Config"

Ce node d√©finit quel mod√®le utiliser :

**Param√®tres** :
- `ai_model` : `"emma"` ou `"gemini"`

**Valeurs** :
- `"emma"` : Utilise Emma via `/api/chat` (Perplexity avec fallback Gemini)
- `"gemini"` : Utilise Gemini directement via l'API Google

**Exemple** :
```json
{
  "ai_model": "emma"
}
```

### Node "Choose AI Model?" (IF)

Ce node route le flux selon le choix :
- **TRUE** (`ai_model === 'emma'`) ‚Üí Branche Emma
- **FALSE** (`ai_model === 'gemini'`) ‚Üí Branche Gemini

## üìã D√©tails des Nodes

### 1. Call /api/chat (Emma)

**URL** : `https://gob-projetsjsls-projects.vercel.app/api/chat`

**M√©thode** : POST

**Body** :
```json
{
  "message": "...",
  "channel": "web",
  "userId": "n8n-automation"
}
```

**Avantages** :
- Utilise Perplexity (recherche web en temps r√©el)
- Fallback automatique vers Gemini si Perplexity √©choue
- Acc√®s aux outils Emma (function calling)
- Analyse financi√®re avanc√©e

### 2. Call Gemini API

**URL** : `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent`

**M√©thode** : POST

**Query Parameters** :
- `key` : `{{ $env.GEMINI_API_KEY }}`

**Body** :
```json
{
  "contents": [{
    "parts": [{
      "text": "..."
    }]
  }],
  "generationConfig": {
    "temperature": 0.7,
    "topK": 40,
    "topP": 0.95,
    "maxOutputTokens": 2048
  }
}
```

**Avantages** :
- Appel direct, pas de d√©pendance sur `/api/chat`
- Plus rapide (pas de fallback)
- Contr√¥le total sur les param√®tres Gemini

### 3. Parse Gemini Response

Ce node adapte la r√©ponse Gemini au format attendu par le reste du workflow.

**Structure Gemini** :
```json
{
  "candidates": [{
    "content": {
      "parts": [{
        "text": "..."
      }]
    }
  }]
}
```

**Format adapt√©** :
```json
{
  "newsletter_content": "...",
  "response": "...",
  "emma_model": "gemini",
  "emma_tools": [],
  "emma_execution_time": 0,
  "trigger_type": "...",
  "prompt_type": "...",
  "generated_at": "...",
  "preview_mode": ...,
  "approved": ...
}
```

## üîß Comment Changer de Mod√®le

### M√©thode 1 : Dans n8n (Interface)

1. Ouvrez le workflow dans n8n
2. Trouvez le node **"AI Model Config"**
3. Modifiez la valeur de `ai_model` :
   - `"emma"` pour utiliser Emma (Perplexity)
   - `"gemini"` pour utiliser Gemini directement
4. Sauvegardez et testez

### M√©thode 2 : Via Script

Modifiez le fichier `n8n-workflow-03lgcA4e9uRTtli1.json` :

```json
{
  "name": "AI Model Config",
  "parameters": {
    "assignments": {
      "assignments": [
        {
          "name": "ai_model",
          "value": "gemini",  // ou "emma"
          "type": "string"
        }
      ]
    }
  }
}
```

Puis importez le workflow dans n8n.

## üìä Comparaison des Mod√®les

| Caract√©ristique | Emma (Perplexity) | Gemini Direct |
|----------------|-------------------|---------------|
| **Recherche Web** | ‚úÖ Oui (Perplexity) | ‚ùå Non |
| **Function Calling** | ‚úÖ Oui (via Emma) | ‚ùå Non |
| **Vitesse** | ‚ö†Ô∏è Plus lent (fallback) | ‚úÖ Plus rapide |
| **Fiabilit√©** | ‚úÖ Haute (fallback) | ‚ö†Ô∏è Moyenne |
| **Co√ªt** | ‚ö†Ô∏è Plus √©lev√© | ‚úÖ Plus bas |
| **Outils Emma** | ‚úÖ Disponibles | ‚ùå Non disponibles |

## üí° Recommandations

### Utiliser Emma (Perplexity) quand :
- Vous avez besoin de donn√©es en temps r√©el
- Vous voulez utiliser les outils Emma (function calling)
- La fiabilit√© est prioritaire (fallback automatique)
- Vous avez besoin d'analyse financi√®re avanc√©e

### Utiliser Gemini Direct quand :
- Vous voulez une r√©ponse rapide
- Vous n'avez pas besoin de recherche web
- Vous voulez r√©duire les co√ªts
- Vous testez des prompts simples

## üö® Notes Importantes

1. **Variable d'environnement** : `GEMINI_API_KEY` doit √™tre configur√©e dans n8n pour la branche Gemini
2. **Format de r√©ponse** : Les deux branches convergent vers "Parse API Response" avec le m√™me format
3. **M√©tadonn√©es** : `emma_model` est d√©fini √† `"perplexity"` pour Emma et `"gemini"` pour Gemini
4. **Preview/Send** : Les valeurs `preview_mode` et `approved` sont pr√©serv√©es dans les deux branches

## üîç D√©pannage

### Probl√®me : Gemini ne r√©pond pas

**V√©rifications** :
1. `GEMINI_API_KEY` est configur√©e dans n8n
2. La cl√© API est valide
3. Le mod√®le `gemini-2.0-flash-exp` est disponible

### Probl√®me : Emma ne r√©pond pas

**V√©rifications** :
1. L'URL `/api/chat` est accessible
2. Les credentials sont corrects
3. Le service Perplexity est op√©rationnel

### Probl√®me : Le flux ne route pas correctement

**V√©rifications** :
1. `ai_model` est bien d√©fini dans "AI Model Config"
2. La condition dans "Choose AI Model?" est correcte
3. Les connexions sont correctes dans le workflow

