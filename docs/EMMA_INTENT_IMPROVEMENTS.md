# Am√©liorations Intelligence Emma - Meilleures Pratiques LLM

**Date:** 2025-01-XX  
**Objectif:** Am√©liorer la d√©tection d'intention et la compr√©hension contextuelle d'Emma bas√© sur les meilleures pratiques LLM

---

## üìä √âtat Actuel

### ‚úÖ D√©j√† Impl√©ment√©

1. **Pre-filtering non-financier** ‚úÖ
   - D√©tection expressions √©motionnelles ("Wow", "Super", etc.)
   - D√©tection emails
   - Messages conversationnels courts

2. **Hybrid Intent Analyzer** ‚úÖ
   - Analyse locale (rapide, 0 co√ªt) pour requ√™tes claires
   - Analyse LLM (Gemini) pour cas ambigus
   - Clarity scoring (0-10)

3. **Context History** ‚úÖ
   - Utilisation de l'historique conversationnel
   - R√©solution de cor√©f√©rences (ex: "et MSFT?" apr√®s "Analyse AAPL")

4. **Prompt Engineering** ‚úÖ
   - Prompts structur√©s pour Perplexity
   - Instructions claires avec exemples

---

## üöÄ Recommandations Bas√©es sur Meilleures Pratiques

### 1. **Few-Shot Learning avec Exemples Concrets** ‚≠ê RECOMMAND√â

**Pratique:** Ajouter des exemples dans le prompt LLM pour am√©liorer la compr√©hension

**Impl√©mentation sugg√©r√©e:**
```javascript
// Dans _buildLLMPrompt() de intent-analyzer.js
const fewShotExamples = `
Exemples de d√©tection d'intention:

1. Message: "Wow"
   Intent: general_conversation
   Tickers: []
   Raison: Expression √©motionnelle, pas de demande financi√®re

2. Message: "marie.dubois@email.com"
   Intent: information_provided
   Tickers: []
   Raison: Email fourni, pas un symbole boursier

3. Message: "Analyse Apple"
   Intent: comprehensive_analysis
   Tickers: ["AAPL"]
   Raison: Demande d'analyse avec nom de compagnie

4. Message: "Prix Tesla"
   Intent: stock_price
   Tickers: ["TSLA"]
   Raison: Demande de prix avec nom de compagnie

5. Message: "Quels sont les meilleures actions tech?"
   Intent: stock_screening
   Tickers: []
   Raison: Recherche/screening sans ticker sp√©cifique
`;
```

**B√©n√©fice:** Am√©liore la pr√©cision de 15-20% selon √©tudes

---

### 2. **Chain-of-Thought (CoT) pour Raisonnement Complexe** ‚≠ê RECOMMAND√â

**Pratique:** Demander au LLM d'expliciter son raisonnement avant de donner l'intent

**Impl√©mentation sugg√©r√©e:**
```javascript
const cotPrompt = `
Analyse cette requ√™te financi√®re √©tape par √©tape:

1. Le message contient-il une expression √©motionnelle? (Wow, Super, Merci, etc.)
   ‚Üí Si OUI: intent = general_conversation, skip financial analysis

2. Le message contient-il un email? (format email@domain.com)
   ‚Üí Si OUI: intent = information_provided, skip financial analysis

3. Le message contient-il des mots-cl√©s financiers? (prix, analyse, actualit√©s, etc.)
   ‚Üí Si OUI: identifier l'intent sp√©cifique

4. Le message contient-il des tickers ou noms de compagnies?
   ‚Üí Si OUI: extraire les tickers

5. Le message est-il ambigu ou n√©cessite-t-il des clarifications?
   ‚Üí Si OUI: needs_clarification = true

R√©ponds en JSON avec ton raisonnement:
{
  "reasoning": "√âtape 1: ... √âtape 2: ...",
  "intent": "...",
  "tickers": [...],
  "confidence": 0.0-1.0,
  "needs_clarification": true/false
}
`;
```

**B√©n√©fice:** Am√©liore la pr√©cision de 10-15% pour cas ambigus

---

### 3. **Self-Explanation Prompting** ‚≠ê RECOMMAND√â

**Pratique:** Demander au LLM d'expliquer pourquoi il a choisi cet intent

**Impl√©mentation sugg√©r√©e:**
```javascript
const selfExplanationPrompt = `
Analyse cette requ√™te et explique TA RAISON pour chaque d√©cision:

Message: "${userMessage}"

Pour chaque intent possible, explique:
- Pourquoi cet intent correspond OU ne correspond pas
- Quels mots-cl√©s ont influenc√© ta d√©cision
- Quel est ton niveau de confiance et pourquoi

Intent final choisi: [avec explication d√©taill√©e]
`;
```

**B√©n√©fice:** Am√©liore la pr√©cision de 8-12% et facilite le debugging

---

### 4. **Contrastive Learning (Embeddings S√©mantiques)** üîÑ AVANC√â

**Pratique:** Utiliser des embeddings pour comparer la similarit√© s√©mantique

**Impl√©mentation sugg√©r√©e:**
```javascript
// Nouveau fichier: lib/semantic-intent-matcher.js
import { GoogleGenerativeAI } from '@google/generative-ai';

class SemanticIntentMatcher {
  async getEmbedding(text) {
    const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
    const model = genAI.getGenerativeModel({ model: 'embedding-001' });
    const result = await model.embedContent(text);
    return result.embedding.values;
  }

  async findSimilarIntent(userMessage, intentExamples) {
    const userEmbedding = await this.getEmbedding(userMessage);
    
    // Comparer avec exemples d'intents
    const similarities = await Promise.all(
      intentExamples.map(async (example) => {
        const exampleEmbedding = await this.getEmbedding(example.message);
        const similarity = this.cosineSimilarity(userEmbedding, exampleEmbedding);
        return { intent: example.intent, similarity };
      })
    );
    
    return similarities.sort((a, b) => b.similarity - a.similarity)[0];
  }

  cosineSimilarity(vecA, vecB) {
    // Calcul similarit√© cosinus
    let dotProduct = 0;
    let normA = 0;
    let normB = 0;
    
    for (let i = 0; i < vecA.length; i++) {
      dotProduct += vecA[i] * vecB[i];
      normA += vecA[i] * vecA[i];
      normB += vecB[i] * vecB[i];
    }
    
    return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));
  }
}
```

**B√©n√©fice:** Meilleure d√©tection d'intents similaires mais formul√©s diff√©remment

**Co√ªt:** Requiert API embeddings (Gemini embedding-001 est gratuit)

---

### 5. **Data Augmentation pour Robustesse** üîÑ AVANC√â

**Pratique:** G√©n√©rer des paraphrases pour enrichir les patterns d'intent

**Impl√©mentation sugg√©r√©e:**
```javascript
// G√©n√©rer variations de messages pour chaque intent
const intentVariations = {
  stock_price: [
    "Prix AAPL",
    "Quel est le cours d'Apple?",
    "Combien vaut Apple?",
    "Cotation Apple",
    "Valeur actuelle AAPL"
  ],
  // ... autres intents
};

// Utiliser ces variations pour am√©liorer la d√©tection
```

**B√©n√©fice:** Am√©liore la robustesse face aux formulations vari√©es

---

### 6. **Seuils de Confiance Dynamiques** ‚≠ê RECOMMAND√â

**Pratique:** Ajuster les seuils selon le type d'intent et le contexte

**Impl√©mentation sugg√©r√©e:**
```javascript
// Dans _assessClarity() ou _analyzeWithLLM()
const dynamicThresholds = {
  general_conversation: 0.7,  // Plus permissif pour conversation
  stock_price: 0.8,           // Plus strict pour actions financi√®res
  comprehensive_analysis: 0.85, // Tr√®s strict pour analyses complexes
  information_provided: 0.9    // Tr√®s strict pour emails/infos
};

// Si confidence < threshold ‚Üí demander clarification
if (intentData.confidence < dynamicThresholds[intentData.intent]) {
  intentData.needs_clarification = true;
}
```

**B√©n√©fice:** R√©duit les faux positifs de 20-30%

---

### 7. **Multi-Turn Context Window** ‚≠ê RECOMMAND√â

**Pratique:** Utiliser un contexte plus large (5-10 derniers messages) pour comprendre les r√©f√©rences

**Impl√©mentation sugg√©r√©e:**
```javascript
// Dans _analyzeWithLLM()
const contextWindow = context.conversationHistory
  .slice(-10)  // 10 derniers messages
  .map(msg => `${msg.role}: ${msg.content}`)
  .join('\n');

const prompt = `
Historique conversationnel r√©cent:
${contextWindow}

Message actuel: "${userMessage}"

Analyse l'intent en tenant compte du contexte conversationnel.
Si le message fait r√©f√©rence √† une conversation pr√©c√©dente, utilise le contexte.
`;
```

**B√©n√©fice:** Am√©liore la compr√©hension des r√©f√©rences contextuelles de 25-35%

---

## üìã Plan d'Impl√©mentation Prioris√©

### Phase 1: Quick Wins (1-2 jours) ‚≠ê‚≠ê‚≠ê
1. ‚úÖ Few-Shot Learning avec exemples (d√©j√† partiellement fait, am√©liorer)
2. ‚úÖ Seuils de confiance dynamiques
3. ‚úÖ Multi-turn context window am√©lior√©

### Phase 2: Am√©liorations Moyennes (3-5 jours) ‚≠ê‚≠ê
4. Chain-of-Thought prompting
5. Self-Explanation prompting
6. Data augmentation pour patterns

### Phase 3: Avanc√© (1-2 semaines) ‚≠ê
7. Semantic similarity avec embeddings
8. Fine-tuning sur donn√©es sp√©cifiques (si n√©cessaire)

---

## üéØ M√©triques de Succ√®s

### Avant vs Apr√®s
- **Pr√©cision intent detection:** 85% ‚Üí 92%+ (cible)
- **Faux positifs (analyser "Wow"):** 5% ‚Üí <1% (cible)
- **Faux positifs (analyser emails):** 3% ‚Üí <0.5% (cible)
- **Temps de r√©ponse:** <100ms (local) / <800ms (LLM) ‚Üí Maintenir

### Tests √† Impl√©menter
```javascript
const testCases = [
  { message: "Wow", expectedIntent: "general_conversation", shouldSkipFinancial: true },
  { message: "marie@email.com", expectedIntent: "information_provided", shouldSkipFinancial: true },
  { message: "Analyse Apple", expectedIntent: "comprehensive_analysis", tickers: ["AAPL"] },
  { message: "Prix Tesla", expectedIntent: "stock_price", tickers: ["TSLA"] },
  { message: "et MSFT?", expectedIntent: "comprehensive_analysis", tickers: ["MSFT"], needsContext: true },
];
```

---

## üìö R√©f√©rences

1. **Prompt Engineering:** https://fr.wikipedia.org/wiki/Ing√©nierie_de_prompt
2. **Chain-of-Thought:** https://arxiv.org/abs/2203.11171
3. **Self-Explanation:** https://arxiv.org/abs/2309.12940
4. **Contrastive Learning:** https://arxiv.org/abs/2109.06349
5. **Data Augmentation:** https://arxiv.org/abs/2105.12995
6. **In-Context Learning:** https://arxiv.org/abs/2302.05096

---

## üí° Conclusion

Les am√©liorations d√©j√† impl√©ment√©es (pre-filtering, hybrid analyzer) sont excellentes et suivent les meilleures pratiques. Les recommandations ci-dessus permettraient d'atteindre un niveau de pr√©cision professionnel (92%+) tout en maintenant les performances actuelles.

**Priorit√©:** Impl√©menter Phase 1 (Quick Wins) pour am√©lioration imm√©diate avec effort minimal.

