/**
 * Script pour s'assurer que "AI Model Config" est correctement connectÃ© dans le flux
 * 
 * Le node doit Ãªtre insÃ©rÃ© aprÃ¨s "Determine Time-Based Prompt" et avant "Prepare API Request"
 */

import { readFileSync, writeFileSync } from 'fs';

const workflowPath = 'n8n-workflow-03lgcA4e9uRTtli1.json';
const workflow = JSON.parse(readFileSync(workflowPath, 'utf-8'));

console.log('ðŸ”§ VÃ©rification de la connexion de "AI Model Config"...\n');

// Trouver les nodes
const determinePromptNode = workflow.nodes.find(n => n.name === 'Determine Time-Based Prompt');
const aiModelConfigNode = workflow.nodes.find(n => n.name === 'AI Model Config');
const prepareApiRequestNode = workflow.nodes.find(n => n.name === 'Prepare API Request');

if (!determinePromptNode || !aiModelConfigNode || !prepareApiRequestNode) {
  console.error('âŒ Nodes requis non trouvÃ©s');
  process.exit(1);
}

// VÃ©rifier la connexion Determine Time-Based Prompt â†’ AI Model Config
if (workflow.connections['Determine Time-Based Prompt']) {
  const currentConnections = workflow.connections['Determine Time-Based Prompt'].main[0];
  const goesToAiModelConfig = currentConnections && currentConnections.find(c => c.node === 'AI Model Config');
  
  if (!goesToAiModelConfig) {
    // Remplacer la connexion directe vers Prepare API Request par AI Model Config
    workflow.connections['Determine Time-Based Prompt'] = {
      main: [
        [
          {
            node: 'AI Model Config',
            type: 'main',
            index: 0
          }
        ]
      ]
    };
    console.log('âœ… Connexion: Determine Time-Based Prompt â†’ AI Model Config');
  } else {
    console.log('âœ… Connexion: Determine Time-Based Prompt â†’ AI Model Config (dÃ©jÃ  correcte)');
  }
} else {
  workflow.connections['Determine Time-Based Prompt'] = {
    main: [
      [
        {
          node: 'AI Model Config',
          type: 'main',
          index: 0
        }
      ]
    ]
  };
  console.log('âœ… Connexion: Determine Time-Based Prompt â†’ AI Model Config (crÃ©Ã©e)');
}

// VÃ©rifier la connexion AI Model Config â†’ Prepare API Request
if (workflow.connections['AI Model Config']) {
  const currentConnections = workflow.connections['AI Model Config'].main[0];
  const goesToPrepareApi = currentConnections && currentConnections.find(c => c.node === 'Prepare API Request');
  
  if (!goesToPrepareApi) {
    workflow.connections['AI Model Config'] = {
      main: [
        [
          {
            node: 'Prepare API Request',
            type: 'main',
            index: 0
          }
        ]
      ]
    };
    console.log('âœ… Connexion: AI Model Config â†’ Prepare API Request (corrigÃ©e)');
  } else {
    console.log('âœ… Connexion: AI Model Config â†’ Prepare API Request (dÃ©jÃ  correcte)');
  }
} else {
  workflow.connections['AI Model Config'] = {
    main: [
      [
        {
          node: 'Prepare API Request',
          type: 'main',
          index: 0
        }
      ]
    ]
  };
  console.log('âœ… Connexion: AI Model Config â†’ Prepare API Request (crÃ©Ã©e)');
}

// Sauvegarder
writeFileSync(workflowPath, JSON.stringify(workflow, null, 2), 'utf-8');

console.log('\nâœ… Flux vÃ©rifiÃ© et corrigÃ© !');
console.log('\nðŸ“‹ Flux final:');
console.log('   Determine Time-Based Prompt');
console.log('   â†’ AI Model Config (choix: emma ou gemini)');
console.log('   â†’ Prepare API Request');
console.log('   â†’ Choose AI Model? (IF)');
console.log('      - TRUE â†’ Call /api/chat (Emma) â†’ Parse API Response');
console.log('      - FALSE â†’ Call Gemini API â†’ Parse Gemini Response â†’ Parse API Response');

